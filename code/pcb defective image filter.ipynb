{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QCrfTOPoh-rlfmSShJ43DPJZDaXztU1d","timestamp":1690803185842}],"gpuType":"T4","mount_file_id":"1QCrfTOPoh-rlfmSShJ43DPJZDaXztU1d","authorship_tag":"ABX9TyPku33YR3XR8QqmCWqLLOgo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"a4dsw2drNG_D"},"outputs":[],"source":["import zipfile\n","\n","def extract_zip_file(zip_file_path, extract_dir):\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","\n","# 압축 파일 경로\n","zip_file_path = '/content/drive/MyDrive/pcbdata/pcb3.zip'\n","\n","# 압축을 풀 폴더 경로\n","extract_dir = '/content/pcb3'\n","\n","# 압축 풀기\n","extract_zip_file(zip_file_path, extract_dir)"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"],"metadata":{"id":"gTKa8H6bO0-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 경로\n","train_dir = '/content/pcb3/traindata'\n","image_size = (512, 512)\n","batch_size = 50"],"metadata":{"id":"ILBbPh8tO1BE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ImageDataGenerator 생성\n","data_generator = ImageDataGenerator(rescale=1./255)\n","\n"],"metadata":{"id":"ClpPK1ksO1DS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 데이터 로더 생성\n","train_generator = data_generator.flow_from_directory(\n","    train_dir,\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LB0JNpiO1Fm","executionInfo":{"status":"ok","timestamp":1690799269391,"user_tz":-540,"elapsed":5,"user":{"displayName":"전효재","userId":"14668335272123637112"}},"outputId":"dcd60ec4-e378-4632-b6d7-52e07e24da4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1150 images belonging to 5 classes.\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(5, activation='softmax')\n","])"],"metadata":{"id":"XFYRlSDlO1IA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"5PtOZojivaOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n"],"metadata":{"id":"ckkV_yzNO1J6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 배치로 학습\n","steps_per_epoch = train_generator.n // batch_size\n","epochs = 10\n","model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs)"],"metadata":{"id":"XBC2h5hZ87SB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","#model.save('/content/drive/MyDrive/pcbdata/model/pcbblur10.h5')\n","#model = keras.models.load_model('/content/drive/MyDrive/pcbdata/model/pcbblur5.h5')"],"metadata":{"id":"vcPuu-5hO1NU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","\n","# 테스트 데이터 준비\n","test_dir = '/content/pcb3/testdata'\n","image_size = (512, 512)\n","batch_size = 250\n","\n","# ImageDataGenerator 생성 (전처리는 훈련 데이터와 동일하게)\n","test_data_generator = ImageDataGenerator(rescale=1./255)\n","\n","# 테스트 데이터 로더 생성\n","test_generator = test_data_generator.flow_from_directory(\n","    test_dir,\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","# 테스트 데이터로 예측 수행\n","y_true = test_generator.classes\n","y_pred_prob = model.predict(test_generator)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","# 정확도 평가\n","accuracy = accuracy_score(y_true, y_pred)\n","print('테스트 데이터 정확도:', accuracy)"],"metadata":{"id":"SkMg6UkEXdqg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sklearn\n","import itertools\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    plt.figure(figsize = (5,5))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","    plt.show()"],"metadata":{"id":"NGX-gmWiYuAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class1 = ['o','g','m','w','r']\n","#Y_pred_classes = np.argmax(Y_pred,axis=1)\n","confusion_mtx = confusion_matrix(y_true, y_pred)\n","plot_confusion_matrix(confusion_mtx, classes = list(class1))"],"metadata":{"id":"WWuLFzMDbHLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","lapp = []\n","def show_images_from_batches(test_generator, num_batches=1):\n","    nn=0\n","    for _ in range(num_batches):\n","        # 제네레이터에서 배치 하나 가져오기\n","        batch = next(test_generator)\n","\n","        # 배치에서 이미지 하나씩 출력\n","        for image in batch[0]:\n","            nn=nn+1\n","            # 이미지 출력 또는 원하는 작업 수행\n","            image_uint8 = (image * 255).astype(np.uint8)\n","\n","            # 그레이스케일 이미지로 변환\n","            gray = cv2.cvtColor(image_uint8, cv2.COLOR_BGR2GRAY)\n","            src = cv2.resize(gray, (256, 256))\n","            gray = src\n","\n","\n","            # 라플라시안 필터 적용\n","            laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n","\n","            # 라플라시안 필터 적용된 이미지에서, 각 값들의 제곱을 구함\n","            dst = cv2.sqrBoxFilter(laplacian, ddepth=-1, ksize=(3,3), normalize=True)\n","\n","            # 분산을 구함 = 제곱의 평균 - 평균의 제곱\n","            z = (dst - (laplacian*laplacian))\n","\n","            # blurred 처리되었다고 판단할 기준값 설정\n","\n","            threshold = 200\n","\n","            z[z<threshold] = 0\n","            z[z>=threshold] = 1\n","\n","\n","\n","\n","\n","            # counting 0 and 1 (0 is blurred, 1 is ok\n","            blurred = z[z==0].shape[0]\n","            normal = z[z==1].shape[0]\n","\n","            # blurred 처리된 영역의 비율 계산\n","            confidence = normal / (blurred+normal)\n","\n","            lapp.append(confidence)\n","\n","show_images_from_batches(test_generator, num_batches=1)"],"metadata":{"id":"RtWqUk9UbH4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#y_pred = np.argmax(y_pred_prob, axis=1)\n","for i in range(0,250):\n","  if lapp[i]>0.78:\n","    y_pred_prob[0] = 1\n","  if lapp[i]<0.36:\n","    y_pred_prob[0] = 0"],"metadata":{"id":"TMvqekmkbH77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","class1 = ['o','g','m','w','r']\n","#Y_pred_classes = np.argmax(Y_pred,axis=1)\n","confusion_mtx = confusion_matrix(y_true, y_pred)\n","plot_confusion_matrix(confusion_mtx, classes = list(class1))"],"metadata":{"id":"HkIOkH3LkuIf"},"execution_count":null,"outputs":[]}]}